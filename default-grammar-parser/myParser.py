#
# CPSC 323 Parser Project
# Authors: Ariadne Rincon, Lea Albano, Desiree Gomez
# Your task is to implement a parser using the default grammar 
# parser csv table generated by the Java program.
#
import csv
from turtle import st
import pandas as pd
from ast import parse


class Parser:
    """
    This class parses the token stream outputted from the lexical analyzer 
    into a parse tree or produces errors if the program is malformed.
    """
    def __init__(self, token_stream, parse_table_file):
        """
        Class constructor takes the token stream output from the 
        lexical analyzer as input. Appends $ to the end of the stream.
        """
        self.token_stream = token_stream
        self.parser_table = self.__read_parse_table(parse_table_file)
        # Append the end of file symbol to the end.
        self.token_stream.append(("$", "$"))
        self.stack = []
        inputContent = self.token_stream

    def __read_parse_table(self, parse_table_file):
        """
        Reads the parse table from a file.
        @param parse_table_file The file path for the parse table csv file.
        @return A dictionary/map (state, symbol) -> action/goto.
        """
        #Professor Psudocode from proj. document
        # Driver:
        # Place $ at the end of the input string 
        file = open("code.txt", "a")
        file.write("$ \n")
        file.close()
        
        file = open("code.txt", "r")
        print("ADDING $ TO END OF STRING: ", file.read())
        file.close()
    
      
        
        # Repeat
        # Let qm be the current state (TOS state) and  i the token
        with open("grammar.txt") as file_in:
            line = []
            tempProductionRulesArray = []
            for lines in file_in:
                line.append(lines)

        return tempProductionRulesArray       
     #raise NotImplementedError()

    def __has_next_token(self):
        """
        @return True if the token stream is not empty.
        """
        return len(self.token_stream) != 0

    def __get_next_token(self):
        """
        Fetches and consumes the next token in the input.
        @return tuple (token, type)
        """
        if self.__has_next_token():
            to_return = self.token_stream[0]
            self.token_stream.pop(0)
            return to_return
        return None

    def parse(self):

        df = pd.DataFrame([["","S3","","",1,2], 
                           ["ACCT","","","","",""],
                           ["","","S4","S5","",""],
                           ["R2","","R4","R4","",""],
                           ["","S6","","","",""],
                           ["","S8","","","",7],
                           ["","","R3","R3","",""],
                           ["R1","","S9","","",""],
                           ["R4","","R4","","",""],
                           ["","S10","","","",""],
                           ["R3","","R3","","",""]],
                           index = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], columns = ["$","id", "+", "=","S","E"])

        # Push state 0 onto the stack 
        myStack = []
        myStack.append(0) 
        print("CURRENT STACK: ", myStack)
        # Prints current stack

        fileObj = open("grammar.txt", "r") #opens the file in read mode
        productionRulesArray = fileObj.read().splitlines() #puts the file into an array
        fileObj.close()

        code = []
        with open('code.txt','r') as file:
            # reading each line    
            for line in file:
                # reading each word        
                for word in line.split():
                    # displaying the words           
                    code.append(word)
        k = 0
        x = ""
        while (x != "ACCT"): #loops until accepting state    
            stack_length = len(myStack)
            qm =  myStack[stack_length - 1] #row
            i =  code[k] #column
            print("INPUT: ", i)
            # Find   x = Table [Qm, i];
            x = df.at[qm, i]
            print("TAKING ACTION: ", x)
            #print(qm, " , ", i , " -> ",x )
        # Case x of
        # S(Qn) : Push (i) and enter qn, i.e., push (Qn);
        
            if (x[0] == "S"):
                myStack.append(i) #push(i)
                myStack.append(x[1]) #push number after S
                # Prints current stack
                print("CURRENT STACK: ", myStack)
                code.pop(k)
                
        #  R(n): Reduce by production #n by popping  2x # of RHS symbols
            elif (x[0] == "R"):
                productionRuleNum = x[1] - 1
                print("PRODUCTION RULE NUM: ", productionRuleNum)
                productionRule = productionRulesArray[productionRuleNum] 
                print("PRODUCTION RULE: ", productionRule)
                #example: productionRule = E -> id
        #  Let Qj be the TOS state
        #  Push  the LHS  L onto the stack
                if(productionRuleNum == (0 | 2)): #If production rule 1 or 3
                    myStack.pop(6)
                    myStack.append("S")
                    # Prints current stack
                    stack_length = myStack.len()
                    Qj = myStack[stack_length - 1] #Gets TOS after popping
                    print("QJ: ", Qj)

                elif ((productionRuleNum) == (1 | 3)): #If production rule 2 or 4
                    myStack.pop(2)
                    # Prints current stack
                    print(myStack)
                    stack_length = myStack.len()
                    Qj = myStack[stack_length - 1] #Gets TOS after popping
                    if(productionRuleNum == 1):
                        myStack.append("S")
                        # Prints current stack
                        print(myStack)
                    elif (productionRuleNum == 3):
                        myStack.append("E")
                        # Prints current stack
                        print(myStack)
                
                L = stack_length - 1

        #  Push Qk = Table [Qj, L] onto the stack
                Qk =df.at[Qj, L]
                myStack.append(Qk)
                # Prints current stack
                print(myStack)
        # ACCT: Parsing is complete
        # Empty:  error condition
        # Until  ACCT or Error
    
        # Error Message
        if (file == " "):
            print("Error Message: Input is an empty string.")
        print(self.__get_next_token())
        #raise NotImplementedError()